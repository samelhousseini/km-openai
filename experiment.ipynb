{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-functions\n",
    "!pip install azure-core\n",
    "!pip install azure-cosmos\n",
    "!pip install openai\n",
    "!pip install numpy\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install azure-storage-blob \n",
    "!pip install azure-identity\n",
    "!pip install smart_open\n",
    "!pip install tenacity\n",
    "!pip install pinecone-client\n",
    "!pip install redis\n",
    "!pip install tiktoken\n",
    "!pip install azure-storage-file-share\n",
    "!pip install python-dotenv\n",
    "!pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "# from utils import redis_helpers\n",
    "# from utils import helpers\n",
    "# from utils import language\n",
    "# from utils import openai_helpers\n",
    "# # from utils import storage\n",
    "# from utils import bot_helpers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index km-openai Deleted\n",
      "Index km-openai created\n",
      "Deleted Skillset - km-openai-skills\n",
      "Created new Skillset - km-openai-skills\n",
      "Deleted Indexer - km-openai-indexer\n",
      "Deleted Data Source - km-openai-skills\n",
      "Created new Data Source Connection - km-openai-docs\n",
      "Created new Indexer - km-openai-indexer\n",
      "Running Indexer km-openai-indexer\n"
     ]
    }
   ],
   "source": [
    "#### Ingest all knowledge base documents\n",
    "from utils import cogsearch_helpers\n",
    "\n",
    "cogsearch_helpers.ingest_kb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reset Index in Redis\n",
    "from utils import redis_helpers\n",
    "\n",
    "reset_index = False\n",
    "\n",
    "if reset_index:\n",
    "    ADA_002_MODEL_MAX_TOKENS = os.environ[\"ADA_002_MODEL_MAX_TOKENS\"] \n",
    "\n",
    "    redis_conn = redis_helpers.get_new_conn()\n",
    "    redis_helpers.redis_reset_index(redis_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET_REDIS = True\n",
    "\n",
    "if RESET_REDIS:\n",
    "    redis_helpers.redis_reset_index(ADA_002_EMBEDDING_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "CHOSEN_EMB_MODEL   = os.environ['CHOSEN_EMB_MODEL']\n",
    "SMALL_EMB_TOKEN_NUM  = int(os.environ['SMALL_EMB_TOKEN_NUM'])\n",
    "MEDIUM_EMB_TOKEN_NUM  = int(os.environ['MEDIUM_EMB_TOKEN_NUM'])\n",
    "LARGE_EMB_TOKEN_NUM  = int(os.environ['LARGE_EMB_TOKEN_NUM'])\n",
    "\n",
    "for item in os.listdir(\"dump\"):\n",
    "    path = os.path.join(\"dump\", item)\n",
    "\n",
    "    with open(path, 'r') as openfile:\n",
    "        data = json.load(openfile)\n",
    "        break\n",
    "\n",
    "emb_documents = []\n",
    "\n",
    "emb_documents += helpers.generate_embeddings(data, CHOSEN_EMB_MODEL, SMALL_EMB_TOKEN_NUM,  text_suffix = 'S')\n",
    "\n",
    "if MEDIUM_EMB_TOKEN_NUM != 0:\n",
    "    emb_documents += helpers.generate_embeddings(data, CHOSEN_EMB_MODEL, MEDIUM_EMB_TOKEN_NUM, text_suffix = 'M')\n",
    "\n",
    "if LARGE_EMB_TOKEN_NUM != 0:\n",
    "    emb_documents += helpers.generate_embeddings(data, CHOSEN_EMB_MODEL, LARGE_EMB_TOKEN_NUM,  text_suffix = 'L')\n",
    "\n",
    "helpers.load_embedding_docs_in_redis(emb_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_documents = []\n",
    "\n",
    "emb_documents += helpers.generate_embeddings_from_json_docs('dump', ADA_002_EMBEDDING_MODEL, ADA_002_MODEL_MAX_TOKENS, text_suffix='XL', limit=-1)\n",
    "\n",
    "print(f\"Generated {len(emb_documents)} embeddings.\")\n",
    "helpers.save_embdding_docs_to_pkl(emb_documents, \"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 141 embeddings into Redis\n"
     ]
    }
   ],
   "source": [
    "emb_documents = helpers.load_embedding_docs_from_pkl(\"test.pkl\")\n",
    "helpers.load_embedding_docs_in_redis(emb_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "        \"in which classes did the Danish sailors qualify?\",\n",
    "        \"what are the reviews of the Lost City hotel?\"\n",
    "    ]\n",
    "\n",
    "\n",
    "for q in queries:\n",
    "    output = bot_helpers.openai_interrogate_text(q, DAVINCI_003_COMPLETIONS_MODEL, ADA_002_EMBEDDING_MODEL, 5, False)\n",
    "    print(\"\\n\\n\", output, '\\n\\n\\n###############################')\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cd1745cb8ae6036b9e0c2149eea914cda9394cff45b1c8e288267fc5648a26d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
